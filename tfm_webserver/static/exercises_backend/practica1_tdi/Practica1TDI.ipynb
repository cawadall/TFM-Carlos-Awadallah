{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Práctica 1</center>\n",
    "** <center>Introduction to digital image processing</center> **\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Reading, writing and viewing images\n",
    "\n",
    "In this notebook we are going to be using 3 python lybraries commonly used for image processing:\n",
    "\n",
    "    -OpenCV: Open Source Computer Vision Library\n",
    "    -Numpy: The fundamental package for scientific computing with Python\n",
    "    -Matplotlib: a Python 2D plotting library\n",
    "The first thing we are going to do is import these libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos librerías necesarias\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to read an image using the function imread from OpenCV. You can find information about it's arguments and output in this [link](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html)\n",
    "\n",
    "It's important to make sure that the image we are trying to read is in the correct directory. If the image is not found python won't raise an exception, imread will return a null array.\n",
    "\n",
    "(Try using print to see your matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgcolor = cv2.imread('lena.jpg') #no 2nd argument needed becouse color is the default\n",
    "imggris = cv2.imread('lena.jpg',0) #when 2nd argument is 0 imread returns a grey image\n",
    "\n",
    "print(imggris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the image we just read we can use the functions size, shape, dtype. \n",
    "[More information about numpy types](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.types.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns number of rows, colums and dimension\n",
    "print('shape:')\n",
    "print(imgcolor.shape)\n",
    "print(imggris.shape)\n",
    "\n",
    "# Returns number of pixels\n",
    "print('size:')\n",
    "print(imgcolor.size)\n",
    "print(imggris.size)\n",
    "\n",
    "# Tpe of matrix\n",
    "print('type:')\n",
    "print(imgcolor.dtype)\n",
    "print(imggris.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the image there are two options: opencv and matplotlib.\n",
    "\n",
    "The opencv option opens the image in a separate window and requires the function waitKey to work. To close the windows you can use the function destroy all windows. [link to more information](https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_gui/py_image_display/py_image_display.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OpenCV\n",
    "\n",
    "cv2.imshow('image',imgcolor)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other option to view images is also imshow but on matplotlib, This option allows the image to appear directly on the notebook. To see the different parameters go to the next [link](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imshow.html), after imshow to actually see the image use the function show from matplotlib\n",
    "\n",
    "Try to view the color image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(imgcolor) #Basics\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(imgcolor)\n",
    "plt.xticks([]), plt.yticks([])  # this hides the axis ticks\n",
    "plt.gca().spines['right'].set_color('none') #Hides the border\n",
    "plt.gca().spines['top'].set_color('none')\n",
    "plt.gca().spines['bottom'].set_color('none')\n",
    "plt.gca().spines['left'].set_color('none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matplotlib also allows the option of zooming the image and a cursor that gives the value of the pixel it's hovering over. When using this option it's important to remember to use plt.figure(), when not used it will paint over the last figure.\n",
    "[About matplotlib notebook](https://medium.com/@1522933668924/using-matplotlib-in-jupyter-notebooks-comparing-methods-and-some-tips-python-c38e85b40ba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.figure(1)\n",
    "plt.imshow(imgcolor)\n",
    "plt.xticks([]), plt.yticks([])  # this hides the axis ticks\n",
    "plt.gca().spines['right'].set_color('none') #Hides the border\n",
    "plt.gca().spines['top'].set_color('none')\n",
    "plt.gca().spines['bottom'].set_color('none')\n",
    "plt.gca().spines['left'].set_color('none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the color image is not correct, this is because of the color space used on OpenCV. OpenCV reads color images as BGR (Blue Green Red), whereas matplotlib represents RGB (Red Green Blue). To see the image correctly is necessary to change color spaces.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to change color spaces\n",
    "\n",
    "OpenCV has a function that allows you to change the color space of an image, it's **cvtcolor**. This function has a lot of possible transformations as you can see executing the next cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flags = flags = [i for i in dir(cv2) if i.startswith('COLOR_')]\n",
    "\n",
    "print(flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the color image we have loaded as an example. We want to change it from BGR to RGB so matplotlib can show the image correcty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform a grey scale image to binary**\n",
    "\n",
    "To go from a color image to gray we can just read de image as a une dimension image with imread, using cvtcolor with the argument COLOR_RGB2GRAY also works.\n",
    "To go from gray to binary we will use de function Threshold, the documentation for this function is in the next [link](https://docs.opencv.org/2.4/modules/imgproc/doc/miscellaneous_transformations.html?highlight=threshold#cv2.threshold)\n",
    "\n",
    "When choosing the intensity level for the threshold it's important to know what you are going to use this binary image for. This threshold can be chosen manually but, there are also algorithms designed to find the best possible threshold, for example Otsu, these algorithms are also possible arguments for the Threshold function.\n",
    "\n",
    "It is also important to choose the maxvalue best suited for your image. Normally binary images use the values 0 and 1, so the max value should be 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(2)\n",
    "imgRGB = cv2.cvtColor(imgcolor, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(imgRGB)\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.gca().spines['right'].set_color('none')\n",
    "plt.gca().spines['top'].set_color('none')\n",
    "plt.gca().spines['bottom'].set_color('none')\n",
    "plt.gca().spines['left'].set_color('none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imggray = cv2.cvtColor(imgRGB, cv2.COLOR_RGB2GRAY)\n",
    "plt.figure('imgray')\n",
    "plt.imshow(imggray, cmap = 'gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "[thresh, imgbi] = cv2.threshold(imggris, 127, 1, cv2.THRESH_BINARY) #with maxvalue 1\n",
    "plt.figure('threshhold 127')\n",
    "plt.imshow(imgbi, cmap = 'gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "[thresh, imgotsu] = cv2.threshold(imggris, 127, 1, cv2.THRESH_OTSU)\n",
    "plt.figure('otsu')\n",
    "plt.imshow(imgotsu, cmap = 'gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "print(thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From binary to color image**\n",
    "\n",
    "To go from a binary image to a RGB image first we need to create a color map. A color map is a matrix that assigns RGB values the different intensity leves in our original image. For example a color map for a binary image is 2X3 matrix, since we have 2 original intensity values, if we had a gay scale 8-bit image we would need a 256X3 color map.\n",
    "\n",
    "To create a color map it's necessary to import the colors from matplotlib, we will be using the function [ListedColorMap](https://matplotlib.org/api/_as_gen/matplotlib.colors.ListedColormap.html#matplotlib.colors.ListedColormap) to create a new color map and apply it to our image.\n",
    "\n",
    "Build manually a color map that makes the white pixels of our image red and the black ones yellow.\n",
    "\n",
    "More information about color maps:[1](https://matplotlib.org/api/_as_gen/matplotlib.colors.Colormap.html#matplotlib.colors.Colormap) [2](https://matplotlib.org/tutorials/colors/colormap-manipulation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colors as mpc\n",
    "color = [[1, 1, 0],\n",
    "       [1, 0, 0]]\n",
    "\n",
    "newcmp = mpc.ListedColormap(color)\n",
    "plt.figure('Colormap')\n",
    "plt.imshow(imgbi, cmap = newcmp)\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Una imagen RGB pase a una imagen indexada con 255 niveles.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Una imagen RGB pase a indexada con 5 niveles.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Una imagen de grises pase a imagen indexada con 5 niveles.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las imágenes procesadas con OpenCV se pueden almacenar en disco utilizando el comando\n",
    "imwrite. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('lenagray.png',imggray)\n",
    "cv2.imwrite('lenabinary.png', imgbi)\n",
    "\n",
    "plt.imsave('lenaind.png', imgbi, cmap = newcmp)\n",
    "#imgind = cv2.imread('cutieind.jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**II. Changing the spatial and intensity resolution of an image **\n",
    "\n",
    "Spatial resolution of an image refers to the number of pixels per row and column. To modify it openCV has the function [resize]( \n",
    "https://docs.opencv.org/2.4/modules/imgproc/doc/geometric_transformations.html#void%20resize(InputArray%20src,%20OutputArray%20dst,%20Size%20dsize,%20double%20fx,%20double%20fy,%20int%20interpolation))\n",
    "\n",
    "Having the gray image of Lena with it's orginal size being 512X512:\n",
    "-Resize it to a 256X256 image\n",
    "-Resize it to a 128X128 image\n",
    "\n",
    "Show the 3 images side by side to apreciate the difference. Using cv2.imshow() it will be easier to see the difference since the windows will be of a different size each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lena_256 = cv2.resize(imggray, None, fx=0.5, fy=0.5)\n",
    "print(Lena_256.shape)\n",
    "Lena_128 = cv2.resize(imggray, None, fx=0.25, fy=0.25)\n",
    "print(Lena_128.shape)\n",
    "\n",
    "plt.figure('Spatial Resolution')\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('Lena 256')\n",
    "plt.imshow(Lena_256, cmap = 'gray')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Lena 128')\n",
    "plt.imshow(Lena_128, cmap = 'gray')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('Lena original')\n",
    "plt.imshow(imggray, cmap = 'gray')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('original',imggray)\n",
    "cv2.imshow('256',Lena_256)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the smaller image from the last question and resize it to it's original spatial resolution using different interpolations (nearest and bilinear). The interpolation is the method used by the resize function to stimate the values of the new pixels created by enlarging an image.\n",
    "Show the 3 images side by side to apreciate the difference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Lena_512a = cv2.resize(Lena_128, None, fx=4, fy=4, interpolation = cv2.INTER_NEAREST)\n",
    "Lena_512b = cv2.resize(Lena_128, None, fx=4, fy=4) #No hace falta especificar bilineal ya que es la que está por defecto\n",
    "\n",
    "plt.figure('Resize')\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('Nearest')\n",
    "plt.imshow(Lena_512a, cmap = 'gray')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Bilinear')\n",
    "plt.imshow(Lena_512b, cmap = 'gray')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('Lena original')\n",
    "plt.imshow(imggray, cmap = 'gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('original',imggray)\n",
    "cv2.imshow('a',Lena_512a)\n",
    "cv2.imshow('b',Lena_512b)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intensity resolution refers to the number of bits used for each pixel wich marks the number of intemsity levels in an image. A normal gray scale image has 8 bits per pixel. A RGB image has 8 bits per pixel multiplied by 3 for each color.\n",
    "\n",
    "To change the intensity resolution of our image we will be using basi math applied directly to our image matrix.\n",
    "\n",
    "-Change the levels of intensity in Lena to 16, 4 and 2 and save them in this variables Lena_512_16, Lena_512_4 y Lena_512_2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for 2 lovels we can use threshold\n",
    "Lena_512_2 = imgotsu\n",
    "\n",
    "#Para reducir a 4 niveles\n",
    "temp = imggray/64\n",
    "temp = np.around(temp)\n",
    "Lena_512_4 = temp*64\n",
    "\n",
    "\n",
    "#Para reducir a 16 niveles\n",
    "temp = imggray/16\n",
    "temp = np.around(temp)\n",
    "Lena_512_16 = temp*16\n",
    "\n",
    "plt.figure('Intensity levels')\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('2')\n",
    "plt.imshow(Lena_512_2, cmap = 'gray')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('4')\n",
    "plt.imshow(Lena_512_4, cmap = 'gray')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('16')\n",
    "plt.imshow(Lena_512_16, cmap = 'gray')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.title('original')\n",
    "plt.imshow(imggray, cmap = 'gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**III. Histograma y mejora de contraste**\n",
    "\n",
    "https://docs.opencv.org/3.1.0/d1/db7/tutorial_py_histogram_begins.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure('Lena_512')\n",
    "plt.hist(imggray.ravel(),256,[0,256]); \n",
    "plt.xlabel('Intensity')\n",
    "plt.ylabel('Number of pixels')\n",
    "plt.show()\n",
    "plt.figure('Lena_512_16')\n",
    "plt.hist(Lena_512_16.ravel(),256,[0,256]);\n",
    "plt.xlabel('Intensity')\n",
    "plt.ylabel('Number of pixels')\n",
    "plt.show()\n",
    "plt.figure('Lena_512_4')\n",
    "plt.hist(Lena_512_4.ravel(),256,[0,256]); \n",
    "plt.xlabel('Intensity')\n",
    "plt.ylabel('Number of pixels')\n",
    "plt.show()\n",
    "plt.figure('Lena_512_2')\n",
    "plt.hist(Lena_512_2.ravel(),255,[0,1]); #In this case the range changes being a binary image\n",
    "plt.xlabel('Intensity')\n",
    "plt.ylabel('Number of pixels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ecualizar el histograma usando la función [equalizehist](https://docs.opencv.org/2.4/modules/imgproc/doc/histograms.html?highlight=equalizehist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pout = cv2.imread('aerial.jpg', 0)\n",
    "plt.hist(pout.ravel(),256,[0,256]);\n",
    "plt.xlabel('Intensity')\n",
    "plt.ylabel('Number of pixels')\n",
    "plt.show()\n",
    "equ = cv2.equalizeHist(pout)\n",
    "plt.hist(equ.ravel(),256,[0,256]); \n",
    "plt.xlabel('Intensity')\n",
    "plt.ylabel('Number of pixels')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(pout, cmap = 'gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()\n",
    "plt.imshow(equ, cmap = 'gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IV.Interpretación del color y transformaciones puntuales**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peppers = cv2.imread('peppers.jpeg')\n",
    "\n",
    "print(peppers.dtype)\n",
    "print(peppers.shape)\n",
    "peppersRGB = cv2.cvtColor(peppers, cv2.COLOR_BGR2RGB)\n",
    "plt.figure()\n",
    "plt.imshow(peppersRGB)\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener el histograma de cada componente R, G, B. Analice y justifique las diferencias\n",
    "entre los histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = ('b','g','r')\n",
    "plt.figure('hist')\n",
    "for i,col in enumerate(color):\n",
    "    histr = cv2.calcHist([peppers],[i],None,[256],[0,256])\n",
    "    plt.plot(histr,color = col)\n",
    "    plt.xlim([0,256])\n",
    "\n",
    "plt.xlabel('Intensity')\n",
    "plt.ylabel('Number of pixels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener el negativo de la componente roja y, con ella, volver a componer una imagen RGB y visualizar el resultado. Justifique los cambios de color respecto a la imagen original teniendo en cuenta el modelo de mezcla de colores correspondiente (modelo aditivo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B,G,R = cv2.split(peppers)\n",
    "plt.figure()\n",
    "plt.imshow(R, cmap = 'gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rinv = 255-R\n",
    "plt.figure()\n",
    "plt.imshow(Rinv, cmap = 'gray')\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "peppersRGBinv = cv2.merge((Rinv,G,B))\n",
    "plt.figure()\n",
    "plt.imshow(peppersRGBinv)\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bnew = np.zeros((425, 640), np.uint8)\n",
    "Gnew = np.zeros((425, 640), np.uint8)\n",
    "peppersRGBred = cv2.merge((R,Gnew,Bnew))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(peppersRGBred)\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.gca().spines['right'].set_color('none')\n",
    "plt.gca().spines['top'].set_color('none')\n",
    "plt.gca().spines['bottom'].set_color('none')\n",
    "plt.gca().spines['left'].set_color('none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
