{"nbformat_minor":1,"cells":[{"source":"# Color Filter Practice - Code \n","cell_type":"markdown","metadata":{}},{"source":"### API Summary Table\n\n| Description                                   | Method                                                       |\n| --------------------------------------------- | ------------------------------------------------------------ |\n| Get the images from your camera               | - `input_image = self.camera.getImage()`                     |\n| Save an RGB image                             | - `self.set_color_image(image_RGB)`                          |\n| Save a BN or filtered image                   | - `self.set_filtered_image(image)`                           |\n| Change the image in RGB to HSV                | - `image_HSV = cv2.cvtColor()`                               |\n| Filter a color (ex: red)                      | - `value_min_HSV = np.array([0, 235, 60])`<br />- `value_max_HSV = np.array([180, 255, 255])` |\n| Filter the images                             | - `image_HSV_filtered = cv2.inRange()`                       |\n| Create a mask with the red values             | - `image_HSV_filtered_Mask = np.dstack(())`                  |\n| Retrieve an image                             | - `imageRGB = cf.get_color_image()`<br />- `filtered = cf.get_filtered_image()`|\n| Show an image in the Notebook                 | - `printImage(cameraImage)`                                  |","cell_type":"markdown","metadata":{}},{"source":"## Program the visual perception logic through your local camera","cell_type":"markdown","metadata":{}},{"source":"To start coding, we need to call ``ColorFilter`` class once. First of all, import the necessary libraries and instance a ColorFilter() object running the code cell below. Note that the `play()` method is used to start the execution of the code. This method will configure the access parameters to the local hardware and initiate a WebSockets connection to the image server. Wait until the ``Color filter is running`` message, and make sure the WebSockets connection is opened by seeking for the corresponding ``Websocket Opened`` message, also reflected in the connection status label at the bottom right of the interface, which will display a message <span style=\"color:white; background:green;\">\"Connected\"</span> once the connection to the image source has been established.","cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":"#! /usr/bin/env python\n#import ipywidgets as w\n\nfrom color_filter import ColorFilter\nimport numpy as np\nimport cv2\n%matplotlib inline\n\n# Init color filter\ncf = ColorFilter()","outputs":[],"metadata":{"trusted":true}},{"source":"Once stablished, you can use ``cf.play()`` to start receving images, and to see the effect of your code in them. As you can see, there are two image viewers available at the rifgth side. The one in the top will always display the streaming of the video source, with no changes. The one below is at your disposal, so you can use it to view the result of your algorithm in the input images. Use the `self.set_color_image(output_img)` to fill the second viewer with any image you want, typically a filtered or processed image.","cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":"cf.play()","outputs":[],"metadata":{"trusted":true}},{"source":"Once our video source is serving images, we can start coding to segment any object. With that putpose, we recommend you to use objects with plain colors, in such a way that the filter values are easier to adjust. We need to modify the ``execute()`` method from Color Filter component with the logic that implements the filter. This method will be called iteratively about 10 times per second. To understand how it works, we are going to print a message in each iteration:","cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":"# Implement execute method\ndef execute(self):\n    print \"Running execute iteration\"\n      \ncf.setExecute(execute)","outputs":[],"metadata":{"trusted":true}},{"source":"Stop printing this \"updating message\" of the method with an empty code:","cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":"def execute(self):\n    #ToDo\n    pass\n\ncf.setExecute(execute)","outputs":[],"metadata":{"trusted":true}},{"source":"**REMEMBER:** You can use the ``pause()`` method of ColorFilter class to do an \"*Academic Pause*\", so that you are able to pause your algorithm, make some changes in the ``execute()`` method and setting those changes as shown above, and then resume your algorithm execution by running the ``play()`` method:\n\n1.- Pause\n```\ncf.pause()\n```\n\n2.- Change execute() method\n```\ndef execute(self):\n    #make some changes\n      \ncf.setExecute(execute)\n```\n3.- Resume\n```\ncf.play()\n```\n\n**Or just execute the buttons above**.","cell_type":"markdown","metadata":{}},{"source":"## Algorithm skeleton\n\nWe provide an skeleton where you can code your color filtering following the steps shown in the theory of this practice:","cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":"def execute(self):\n      \n    # Get image\n    input_image = self.camera.getImage()\n    if input_image is None:\n        print \"Can't get images from camera, is your local camera working?\"\n        return\n    \n    if input_image.any(): \n        output_img = np.copy(input_image)\n        \n        # Smooth image\n        # Add your code here\n        \n        # RGB to HSV conversion\n        # Add your code here\n        \n        # Color filter\n        # Add your code here\n        \n        # Rectangle approximation\n        # Add your code here\n        \n        # Box detection\n        # Add your code here\n\n        # Save images\n        self.set_color_image(output_img)\n        #self.set_filtered_image(thresold_img)\n\ncf.setExecute(execute)","outputs":[],"metadata":{"trusted":true}},{"source":"---\n## SOLUTION","cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":"def execute(self):\n\n    im = self.camera.getImage()\n    if im is not None:\n        input_image = np.copy(im) \n        smooth_image = cv2.GaussianBlur(input_image,(5,5),0)\n        HSV_smooth_image = cv2.cvtColor(smooth_image, cv2.COLOR_RGB2HSV)\n        lower_boundary = np.array([110,155,0], dtype = \"uint8\")\n        upper_boundary = np.array([179,255,255], dtype = \"uint8\")\n\n        # PARA UN OBJETO AZUL\n        lower_boundary2 = np.array([109,0,0], dtype = \"uint8\")\n        upper_boundary2 = np.array([128,255,255], dtype = \"uint8\")\n        # -------------------\n\n        mask = cv2.inRange(HSV_smooth_image,lower_boundary,upper_boundary)\n        mask2 = cv2.inRange(HSV_smooth_image,lower_boundary2,upper_boundary2)\n        #self.camera.set_filtered_image(mask)\n        input_image_copy = input_image\n\n        mask_copy2 = np.copy(mask2)\n        im2_2, contours2, hierarchy2 = cv2.findContours(mask_copy2,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n        if contours2 != []:\n            contour = sorted(contours2, key = cv2.contourArea, reverse = True)[0] \n            # Ordenamos los contornos por su area (de mayor a menor)\n            x,y,w,h = cv2.boundingRect(contour)\n            rectangle = cv2.rectangle(input_image_copy, (x,y), (x+w,y+h),(255,117,20),2)\n            self.set_filtered_image(rectangle)\n\ncf.setExecute(execute)","outputs":[],"metadata":{"trusted":true}},{"execution_count":null,"cell_type":"code","source":"","outputs":[],"metadata":{"trusted":true}}],"nbformat":4,"metadata":{"kernelspec":{"display_name":"Python 2","name":"python2","language":"python"},"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","version":"2.7.12","name":"python","file_extension":".py","pygments_lexer":"ipython2","codemirror_mode":{"version":2,"name":"ipython"}},"celltoolbar":"Edit Metadata"}}