{"nbformat_minor":2,"cells":[{"source":"# Follow_Line Practice","cell_type":"markdown","metadata":{}},{"source":"### API Summary Table\n| Description                                   | Method                                                       |\n| --------------------------------------------- | ------------------------------------------------------------ |\n| Get the images from the camera                | - `input_image = self.getImage()`                            |\n| Move the robot                                | - `self.motors.sendW(5)` <br />-  `self.motors.sendV(10)`          |\n| Change the image inRGB to HSV                 | - `image_HSV = cv2.cvtColor()`                               |\n| Filter the red values                         | - `value_min_HSV = np.array([0, 235, 60])`<br />- `value_max_HSV = np.array([180, 255, 255])` |\n| Filter the images                             | - `image_HSV_filtered = cv2.inRange()`                       |\n| Create a mask with the red values             | - `image_HSV_filtered_Mask = np.dstack(())`                  |\n| Get the numbers of the image rows and columns | - `size = input_image.shape`                                 |\n| Get the pixels that change of tone            | - `position_pixel_left = []`<br />- `position_pixel_right = []` |\n| Calculate the desviation of the car           | -   `desviation = position_middle - (columns/2)`             |\n| Save the camera image                         | - `self.set_color_image(input_image)`                        |\n| Save the filtered image                       | - `self.set_threshold_image(image_HSV_filtered_Mask)`        |\n| Show an image                                 | - `printImage(img)`                                          |      ","cell_type":"markdown","metadata":{}},{"source":"### Exercise initialization\n---\nFirst of all, we need to run the Gazebo simulator. The environment and the robot models are automatically launched, as you can see in the right side of the screen. If you are not seeing something similar to the image shown below, ensure to zoom out a little bit to seek for them:\n\n<img src=\"world.png\">","cell_type":"markdown","metadata":{}},{"source":"Second, we need to import the necessary files. Once done, we need to call `Follow_Line` class once. Run this code and wait a few seconds until follow line initialization finishes with an OK message:","cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":"#!/usr/bin/python\n#-*- coding: utf-8 -*-\n\nfrom local_follow_line import FollowLine, printImage\n%matplotlib inline\n\nfl = FollowLine()\nfl.play()","outputs":[],"metadata":{"trusted":true}},{"source":"Now we can start coding to give intelligence to the Formula1 robot. We can do it modifying the `execute()` method from Follow Line component. This method will be called iteratively. Let's try it with a dummy instruction: each iteration, we'll print a message.","cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":"# Implement execute method\ndef execute(self):\n    print \"Running execute iteration\"\n      \nfl.setExecute(execute)","outputs":[],"metadata":{"trusted":true}},{"source":"Stop printing the updating (message) of the method with an empty instruction:","cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":"def execute(self):\n    pass\n    # your code goes here\nfl.setExecute(execute)","outputs":[],"metadata":{"trusted":true}},{"source":"Now you have seen how the `execute` method materializes the changes in the `FollowLine` component, just include there your code. Cheer Up!","cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":"import cv2\nimport numpy as np\ndef execute(self):\n    #GETTING THE IMAGES\n    input_image = self.getImage()\n\n    # RGB model change to HSV\n    image_HSV = cv2.cvtColor(input_image, cv2.COLOR_RGB2HSV)\n\n    # Minimum and maximum values of the red ​​\n    value_min_HSV = np.array([0, 235, 60])\n    value_max_HSV = np.array([180, 255, 255])\n\n    # Filtering images\n    image_HSV_filtered = cv2.inRange(image_HSV, value_min_HSV, value_max_HSV)\n\n    # Creating a mask with only the pixels within the range of red\n    image_HSV_filtered_Mask = np.dstack((image_HSV_filtered, image_HSV_filtered, image_HSV_filtered))\n\n    # Shape gives us the number of rows and columns of an image\n    size = input_image.shape\n    rows = size[0]\n    columns = size[1]\n\n    #  Looking for pixels that change of tone\n    position_pixel_left = []\n    position_pixel_right  = []\n\n    for i in range(0, columns-1):\n        value = image_HSV_filtered[365, i] - image_HSV_filtered[365, i-1]\n        if(value != 0):\n            if (value == 255):\n                position_pixel_left.append(i)\n            else:\n                position_pixel_right.append(i-1)\n\n    # Calculating the intermediate position of the road\n    if ((len(position_pixel_left) != 0) and (len(position_pixel_right) != 0)):\n        position_middle = (position_pixel_left[0] + position_pixel_right[0]) / 2\n    elif ((len(position_pixel_left) != 0) and (len(position_pixel_right) == 0)):\n        position_middle = (position_pixel_left[0] + columns) / 2\n    elif ((len(position_pixel_left) == 0) and (len(position_pixel_right) != 0)):\n        position_middle = (0 + position_pixel_right[0]) / 2\n    else:\n        position_pixel_right.append(1000)\n        position_pixel_left.append(1000)\n        position_middle = (position_pixel_left[0] + position_pixel_right[0])/ 2\n\n    # Calculating the desviation\n    desviation = position_middle - (columns/2)\n    print (\"desviation: \", desviation)\n\n    #EXAMPLE OF HOW TO SEND INFORMATION TO THE ROBOT ACTUATORS\n    if (desviation == 0):\n         self.motors.sendV(3)\n    elif (position_pixel_right[0] == 1000):\n         self.motors.sendW(-0.35)\n    elif ((abs(desviation)) < 85):\n         if ((abs(desviation)) < 15):\n             self.motors.sendV(1)\n         else:\n             self.motors.sendV(3.5)\n         self.motors.sendW(-0.00045 * desviation)\n    elif ((abs(desviation)) < 150):\n         if ((abs(desviation)) < 120):\n             self.motors.sendV(1)\n         else:\n             self.motors.sendV(1)\n         self.motors.sendW(-0.00045 * desviation)\n    else:\n         self.motors.sendV(1)\n         self.motors.sendW(-0.0055 * desviation)\n\n    # Saving the filtered image\n    self.set_threshold_image(image_HSV_filtered_Mask)\n        \nfl.setExecute(execute)","outputs":[],"metadata":{"trusted":true}},{"source":"### Just a few Examples and Tips\n\nTo obtain an image of the camera, the data is first saved and then displayed. You can use these instructions to display the contents of the camera.","cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":"def execute(self):\n    img = self.getImage()\n    self.set_color_image(img)\n    printImage(img)\n    \nfl.setExecute(execute)","outputs":[],"metadata":{"trusted":true}},{"source":"You can use the following instructions to show the filtered images:","cell_type":"markdown","metadata":{}},{"execution_count":null,"cell_type":"code","source":"def execute(self):\n    img = self.getImage()\n    filtered_img = None\n    # image processing...\n    # filtered_img = foo\n    self.set_threshold_image(filtered_img)\n    printImage(filtered_img)\n    \nfl.setExecute(execute)","outputs":[],"metadata":{"trusted":true}},{"execution_count":null,"cell_type":"code","source":"def execute(self):\n    segmentedImage = fl.get_threshold_image()\n    printImage(segmentedImage)\n    \nfl.setExecute(execute)","outputs":[],"metadata":{"trusted":true}}],"nbformat":4,"metadata":{"kernelspec":{"display_name":"Python 2","name":"python2","language":"python"},"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","version":"2.7.12","name":"python","file_extension":".py","pygments_lexer":"ipython2","codemirror_mode":{"version":2,"name":"ipython"}}}}